{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load main.py\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from utility.utility import postp, GramMatrix, GramMSELoss, load_images, save_images, make_folders\n",
    "from utility.loss_fns import get_style_patch_weights, patch_difference, mrf_loss_fn, weight_maker\n",
    "from utility.vgg_network import VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# style weights\n",
    "sw1=1\n",
    "sw2=1\n",
    "sw3=1\n",
    "sw4=1\n",
    "sw5=1\n",
    "# Content weights\n",
    "cw1=0\n",
    "cw2=0\n",
    "cw3=0\n",
    "cw4=1\n",
    "cw5=0\n",
    "#############################################################################\n",
    "# Get image paths and names\n",
    "# Style 1\n",
    "style_dir1  = os.path.dirname('../input/font_contents/serif_removal/NotoSans-Regular.png')\n",
    "style_name1 = os.path.basename('../input/font_contents/serif_removal/NotoSans-Regular.png')\n",
    "# Style 2\n",
    "style_dir2  = os.path.dirname('../input/font_contents/serif_removal/NotoSerif-Regular.png')\n",
    "style_name2 = os.path.basename('../input/font_contents/serif_removal/NotoSerif-Regular.png')\n",
    "# Content\n",
    "content_dir  = os.path.dirname('../input/font_contents/serif_removal/PT_Serif-Caption-Web-Italic.png')\n",
    "content_name = os.path.basename('../input/font_contents/serif_removal/PT_Serif-Caption-Web-Italic.png')\n",
    "\n",
    "# Cuda device\n",
    "if torch.cuda.is_available:\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(\"Using device: \", device)\n",
    "\n",
    "# Parameters\n",
    "alpha = 1\n",
    "beta = 1\n",
    "patch_size = 5\n",
    "image_size = 256\n",
    "content_invert = 1\n",
    "style_invert = 1\n",
    "result_invert = content_invert\n",
    "\n",
    "# Get output path\n",
    "output_path = '../output_style_difference/direct/'\n",
    "try:\n",
    "    os.mkdir(output_path)\n",
    "except:\n",
    "    pass\n",
    "output_path = output_path + content_name[:-4] + '_' + style_name1[:-4] + '_' + style_name2[:-4] + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get network\n",
    "vgg = VGG()\n",
    "vgg.load_state_dict(torch.load('../Models/vgg_conv.pth'))\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "vgg.to(device)\n",
    "\n",
    "# Load images\n",
    "content_image = load_images(os.path.join(content_dir, content_name), image_size, device, content_invert)\n",
    "style_image1  = load_images(os.path.join(style_dir1,style_name1), image_size, device, style_invert)\n",
    "style_image2  = load_images(os.path.join(style_dir2,style_name2), image_size, device, style_invert)\n",
    "\n",
    "# Random input\n",
    "# opt_img = Variable(torch.randn(content_image.size()).type_as(content_image.data).to(device), requires_grad=True).to(device)\n",
    "# Content input\n",
    "opt_img = Variable(content_image.data.clone(), requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define layers, loss functions, weights and compute optimization targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define layers, loss functions, weights and compute optimization targets\n",
    "# Style layers\n",
    "style_layers = ['r12','r22','r34','r44','r54'] \n",
    "style_weights = [sw*1e3/n**2 for sw,n in zip([sw1,sw2,sw3,sw4,sw5],[64,128,256,512,512])]\n",
    "# style_weights = [1,1,1,1,1]\n",
    "# Content layers\n",
    "#content_layers = ['r12','r22','r32','r42','r52']\n",
    "# content_layers = ['r31','r32','r33','r34','r41']\n",
    "content_layers = ['r41']\n",
    "content_weights = [1e4]\n",
    "# content_weights = [cw1*1e4,cw2*1e4,cw3*1e4,cw4*1e4,cw5*1e4]\n",
    "\n",
    "loss_layers = style_layers + content_layers\n",
    "loss_functions = [GramMSELoss()] * len(style_layers) + [nn.MSELoss()] * len(content_layers)\n",
    "loss_functions = [loss_fn.to(device) for loss_fn in loss_functions]\n",
    "weights = style_weights + content_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute optimization targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute optimization targets\n",
    "### Gram matrix targets\n",
    "\n",
    "# Feature maps from style layers of the style images\n",
    "style1_fms_style = [A.detach() for A in vgg(style_image1, style_layers)]\n",
    "style2_fms_style = [A.detach() for A in vgg(style_image2, style_layers)]\n",
    "# Gram matrices of style feature maps\n",
    "style1_gramm = [GramMatrix()(A) for A in style1_fms_style]\n",
    "style2_gramm = [GramMatrix()(A) for A in style2_fms_style]\n",
    "# Difference between gram matrices of style1 and style2\n",
    "gramm_style = [(style1_gramm[i] - style2_gramm[i])**2 for i in range(len(style_layers))]\n",
    "\n",
    "# Feature maps from style layers of the content image\n",
    "content_fms_style = [A.detach() for A in vgg(content_image, style_layers)]\n",
    "content_gramm = [GramMatrix()(A) for A in content_fms_style]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Content targets\n",
    "# Feature maps from content layers of the style images\n",
    "style1_fms_content = [A.detach() for A in vgg(style_image1, content_layers)]\n",
    "style2_fms_content = [A.detach() for A in vgg(style_image2, content_layers)]\n",
    "# Difference between feature maps\n",
    "style_fms_content = [(style1_fms_content[i] - style2_fms_content[i])**2 for i in range(len(content_layers))]\n",
    "# Feature maps from content layers of the content image\n",
    "content_fm_content = [A.detach() for A in vgg(content_image, content_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run style transfer\n",
    "make_folders(output_path)\n",
    "\n",
    "max_iter = 1000\n",
    "show_iter = 50\n",
    "optimizer = optim.LBFGS([opt_img])\n",
    "n_iter=[0]\n",
    "loss_list = []\n",
    "c_loss = []\n",
    "s_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Content loss: 2.325425431563469e+16\n",
      "Style loss  : 2.5350179028729856e+16\n",
      "Total loss  : 4.860443549184819e+16\n",
      "Iteration: 50\n",
      "Content loss: 2.288276756181811e+16\n",
      "Style loss  : 1.4473226964959232e+16\n",
      "Total loss  : 3.735599345303552e+16\n",
      "Iteration: 100\n",
      "Content loss: 2.287637879796531e+16\n",
      "Style loss  : 1.2941746853904384e+16\n",
      "Total loss  : 3.581812457812787e+16\n",
      "Iteration: 150\n",
      "Content loss: 2.2872272809230336e+16\n",
      "Style loss  : 1.2494530162982912e+16\n",
      "Total loss  : 3.53668008247296e+16\n",
      "Iteration: 200\n",
      "Content loss: 2.287035725381632e+16\n",
      "Style loss  : 1.2263357843243008e+16\n",
      "Total loss  : 3.513371509705933e+16\n",
      "Iteration: 250\n",
      "Content loss: 2.286971086123827e+16\n",
      "Style loss  : 1.21227867848704e+16\n",
      "Total loss  : 3.4992498719850496e+16\n",
      "Iteration: 300\n",
      "Content loss: 2.2870737358422016e+16\n",
      "Style loss  : 1.2025745220042752e+16\n",
      "Total loss  : 3.489648257846477e+16\n",
      "Iteration: 350\n",
      "Content loss: 2.28713987833856e+16\n",
      "Style loss  : 1.1952767283232768e+16\n",
      "Total loss  : 3.482416606661837e+16\n",
      "Iteration: 400\n",
      "Content loss: 2.287079748796416e+16\n",
      "Style loss  : 1.1893778054905856e+16\n",
      "Total loss  : 3.4764575542870016e+16\n",
      "Iteration: 450\n",
      "Content loss: 2.286931572424704e+16\n",
      "Style loss  : 1.1849006242070528e+16\n",
      "Total loss  : 3.4718320892575744e+16\n",
      "Iteration: 500\n",
      "Content loss: 2.286824198242304e+16\n",
      "Style loss  : 1.1812495798829056e+16\n",
      "Total loss  : 3.4680737781252096e+16\n",
      "Iteration: 550\n",
      "Content loss: 2.286755693513933e+16\n",
      "Style loss  : 1.178271664308224e+16\n",
      "Total loss  : 3.465027143073792e+16\n",
      "Iteration: 600\n",
      "Content loss: 2.2866904100110336e+16\n",
      "Style loss  : 1.1758548862107648e+16\n",
      "Total loss  : 3.4625452962217984e+16\n",
      "Iteration: 650\n",
      "Content loss: 2.286643809615872e+16\n",
      "Style loss  : 1.17373671571456e+16\n",
      "Total loss  : 3.4603804179562496e+16\n",
      "Iteration: 700\n",
      "Content loss: 2.2866173955670016e+16\n",
      "Style loss  : 1.1718744178950144e+16\n",
      "Total loss  : 3.4584919208361984e+16\n",
      "Iteration: 750\n",
      "Content loss: 2.2865864718024704e+16\n",
      "Style loss  : 1.1702598323142656e+16\n",
      "Total loss  : 3.456846304116736e+16\n",
      "Iteration: 800\n",
      "Content loss: 2.286579385106432e+16\n",
      "Style loss  : 1.1687398433882112e+16\n",
      "Total loss  : 3.455319228494643e+16\n",
      "Iteration: 850\n",
      "Content loss: 2.286578096616243e+16\n",
      "Style loss  : 1.1672450873950208e+16\n",
      "Total loss  : 3.4538230766370816e+16\n",
      "Iteration: 900\n",
      "Content loss: 2.2865746606424064e+16\n",
      "Style loss  : 1.1658687651250176e+16\n",
      "Total loss  : 3.452443747889971e+16\n",
      "Iteration: 950\n",
      "Content loss: 2.286566500204544e+16\n",
      "Style loss  : 1.1645903681093632e+16\n",
      "Total loss  : 3.451156760939725e+16\n",
      "Iteration: 1000\n",
      "Content loss: 2.286555762786304e+16\n",
      "Style loss  : 1.1635024528932864e+16\n",
      "Total loss  : 3.450058108305408e+16\n"
     ]
    }
   ],
   "source": [
    "while n_iter[0] <= max_iter:\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        out = vgg(opt_img, loss_layers)\n",
    "        content_layer_losses = []\n",
    "        style_layer_losses  = []\n",
    "        \n",
    "        opt_fms_style = []\n",
    "        opt_fms_content = []\n",
    "        # Divide between style feature maps and content feature maps\n",
    "        for i, A in enumerate(out):\n",
    "            if i < len(style_layers):\n",
    "                opt_fms_style.append(A)\n",
    "            else:\n",
    "                opt_fms_content.append(A)\n",
    "\n",
    "        ## Difference between feature maps on style layers\n",
    "#        diff_fms_style = [opt_fms_style[i] - content_fms_style[i] for i in range(len(style_layers))]\n",
    "#        gramm_diff = [GramMatrix()(A) for A in diff_fms_style]\n",
    "        ## Difference between gram matrix of feature map differences\n",
    "#        style_layer_losses = [style_weights[i]*(nn.MSELoss()(gramm_diff[i], gramm_style[i])) for i in range(len(style_layers))]\n",
    "        \n",
    "        opt_gramm = [GramMatrix()(A) for A in opt_fms_style]\n",
    "        gramm_diff = [(opt_gramm[i] - content_gramm[i]) for i in range(len(style_layers))]\n",
    "        style_layer_losses = [style_weights[i]*nn.MSELoss()(gramm_diff[i], gramm_style[i]) for i in range(len(style_layers))]\n",
    "\n",
    "        ## Difference between feature maps on content layers\n",
    "        fms_diff = [(opt_fms_content[i] - content_fm_content[i]) for i in range(len(content_layers))]\n",
    "        content_layer_losses = [content_weights[i]*nn.MSELoss()(fms_diff[i],style_fms_content[i]) for i in range(len(content_layers))]\n",
    "        \n",
    "\n",
    "        # losses\n",
    "        content_loss = sum(content_layer_losses)\n",
    "        style_loss   = sum(style_layer_losses)\n",
    "        \n",
    "        # ld1 = len(str(content_loss.item()))\n",
    "        # ld2 = len(str(style_loss.item()))\n",
    "        # if ld1 > ld2:\n",
    "        #     div = ld1 - ld2\n",
    "        #     style_loss = style_loss*(10**(div))\n",
    "        # else:\n",
    "        #     div = ld2 - ld1\n",
    "        #     content_loss = content_loss*(10**(div))\n",
    "        \n",
    "        \n",
    "        layer_losses = content_layer_losses + style_layer_losses\n",
    "\n",
    "        # total loss\n",
    "        loss = sum(layer_losses)\n",
    "\n",
    "        # for log\n",
    "        c_loss.append(content_loss)\n",
    "        s_loss.append(style_loss)\n",
    "        loss_list.append(loss)\n",
    "\n",
    "        # backward calculation\n",
    "        loss.backward()\n",
    "\n",
    "        #print loss\n",
    "        if n_iter[0]%show_iter == 0:\n",
    "            print('Iteration: {}'.format(n_iter[0]))\n",
    "            print('Content loss: {}'.format(content_loss.item()))\n",
    "            print('Style loss  : {}'.format(style_loss.item()))\n",
    "            print('Total loss  : {}'.format(loss.item()))\n",
    "\n",
    "            # Save loss graph\n",
    "            plt.plot(loss_list, label='Total loss')\n",
    "            plt.plot(c_loss, label='Content loss')\n",
    "            plt.plot(s_loss, label='Style loss')\n",
    "            plt.legend()\n",
    "            plt.savefig(output_path + 'loss_graph.jpg')\n",
    "            plt.close()\n",
    "            # Save optimized image\n",
    "            out_img = postp(opt_img.data[0].cpu().squeeze(), image_size, result_invert)\n",
    "            out_img.save(output_path + 'outputs/{}.bmp'.format(n_iter[0]))\n",
    "\n",
    "        n_iter[0] += 1\n",
    "        return loss\n",
    "      \n",
    "    optimizer.step(closure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(content_image.data[0].cpu().squeeze(), opt_img.data[0].cpu().squeeze(), style_image1.data[0].cpu().squeeze(), style_image2.data[0].cpu().squeeze(), image_size, output_path, n_iter, content_invert, style_invert, result_invert)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
