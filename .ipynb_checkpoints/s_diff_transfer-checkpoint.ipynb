{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load main2.py\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utility.utility import postp, GramMatrix, GramMSELoss, load_image, save_images, make_folders\n",
    "from utility.vgg_network import VGG\n",
    "from utility.loss_fns import get_style_patch_weights, smoothnes_loss, content_loss_fn, mrf_loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Get image paths\n",
    "# Content\n",
    "content_dir = os.path.dirname(\"../input/font_contents/AlegreyaSans-Light/A.png\")\n",
    "content_name = os.path.basename(\"../input/font_contents/AlegreyaSans-Light/A.png\")\n",
    "# Style 1\n",
    "style_dir1  = os.path.dirname(\"../input/font_contents/serif/A/Italianno-Regular.png\")\n",
    "style_name1 = os.path.basename(\"../input/font_contents/serif/A/Italianno-Regular.png\")\n",
    "# Style 2\n",
    "style_dir2  = os.path.dirname(\"../input/font_contents/serif_rmv/A/Italianno-Regular.png\")\n",
    "style_name2 = os.path.basename(\"../input/font_contents/serif_rmv/A/Italianno-Regular.png\")\n",
    "\n",
    "# Parameters\n",
    "image_size = 256\n",
    "patch_size = 5\n",
    "alpha = 1e-1\n",
    "beta  = 1e-1\n",
    "gamma = 1e-6\n",
    "content_invert = 1\n",
    "style_invert = 1\n",
    "result_invert = content_invert\n",
    "\n",
    "# Cuda device\n",
    "if torch.cuda.is_available:\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(\"Using device: \", device)\n",
    "\n",
    "# Output path\n",
    "output_path = \"../style_difference_output/\"\n",
    "try:\n",
    "    os.mkdir(output_path)\n",
    "except:\n",
    "    pass\n",
    "output_path = output_path + content_name[:-4] + '_' + style_name1[:-4] + '_' + style_name2[:-4] + '/'\n",
    "try:\n",
    "    os.mkdir(output_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get network\n",
    "vgg = VGG()\n",
    "vgg.load_state_dict(torch.load('../Models/vgg_conv.pth'))\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "vgg.to(device)\n",
    "\n",
    "# Load images\n",
    "content_img = load_image(os.path.join(content_dir, content_name), image_size, device, content_invert)\n",
    "style_img1 = load_image(os.path.join(style_dir1,style_name1), image_size, device, style_invert)\n",
    "style_img2 = load_image(os.path.join(style_dir2,style_name2), image_size, device, style_invert)\n",
    "\n",
    "# Random input\n",
    "opt_img = Variable(torch.randn(content_img.size()).type_as(content_img.data).to(device), requires_grad=True).to(device)\n",
    "# Content input\n",
    "# opt_img = Variable(content_img.data.clone(), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define style layers\n",
    "style_layers = ['r11','r21','r31','r41','r51']\n",
    "style_weights = [1e3/n**3 for n in [64,128,256,512,512]]\n",
    "# Define mrf layers\n",
    "mrf_layers = ['r31', 'r41'] \n",
    "# Defince content layers\n",
    "content_layers = ['r42']\n",
    "content_weights = [1e0]\n",
    "# loss layers: layers to be used by opt_img ( style_layers & mrf_layers & content_layers)\n",
    "loss_layers = mrf_layers + style_layers + content_layers\n",
    "\n",
    "# Feature maps from style image 1\n",
    "mrf_fms1 = [A.detach() for A in vgg(style_img1, mrf_layers)]\n",
    "# Extract style patches & create conv3d from those patches 1 \n",
    "style_patches_lists1, weight_list1 = get_style_patch_weights(mrf_fms1, device, k=patch_size)\n",
    "# Compute style target 1\n",
    "style_targets1 = [GramMatrix()(A).detach() for A in vgg(style_img1, style_layers)]\n",
    "\n",
    "# Feature maps from style image 2\n",
    "mrf_fms2 = [A.detach() for A in vgg(style_img2, mrf_layers)]\n",
    "# Extract style patches & create conv3d from those patches 2\n",
    "style_patches_lists2, weight_list2 = get_style_patch_weights(mrf_fms2, device, k=patch_size)\n",
    "# Compute style target 2\n",
    "style_targets2 = [GramMatrix()(A).detach() for A in vgg(style_img2, style_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_patches_lists = style_patches_lists1.copy()\n",
    "weight_list = weight_list1.copy()\n",
    "style_targets = style_targets1.copy()\n",
    "\n",
    "# Difference between style patches list\n",
    "for i,style_patches_list in enumerate(style_patches_lists):\n",
    "    for j,style_patch in enumerate(style_patches_list):\n",
    "        style_patch = torch.abs_(style_patches_lists1[i][j] - style_patches_lists1[i][j])\n",
    "\n",
    "# Difference between 3D weights\n",
    "for i,weights in enumerate(weight_list):\n",
    "    weights = torch.abs_(weight_list1[i]-weight_list2[i])\n",
    "\n",
    "# Difference between Gram matrices\n",
    "for i, style_target in enumerate(style_targets):\n",
    "    style_target = torch.abs_(style_targets1[i]-style_targets2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 1/50 [00:01<01:12,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Content loss : 38439.99375\n",
      "Style loss   : 269333.0\n",
      "MRF loss     : 9829618.81088\n",
      "Regulari loss: 785.8258125\n",
      "Total loss   : 10138178.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [01:07,  1.37s/it]                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50\n",
      "Content loss : 64009.53125\n",
      "Style loss   : 100615.15625\n",
      "MRF loss     : 6180478.910464\n",
      "Regulari loss: 195610.352\n",
      "Total loss   : 6540714.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [01:19,  1.36s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'style_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-fc64521ead98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# Save sum images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0msave_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnaming_it\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_invert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_invert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_invert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'style_img' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute content target\n",
    "content_targets = [A.detach() for A in vgg(content_img, content_layers)]\n",
    "\n",
    "# targets\n",
    "targets = style_targets + content_targets\n",
    "# layers weights\n",
    "weights = style_weights + content_weights\n",
    "# Optimizing layers\n",
    "loss_fns = [GramMSELoss()] * len(style_layers) + [nn.MSELoss()] * len(content_layers)\n",
    "loss_fns = [loss_fn.to(device) for loss_fn in loss_fns]\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.LBFGS([opt_img])\n",
    "\n",
    "n_iter = [0]\n",
    "naming_it = [0]\n",
    "loss_list = []\n",
    "content_loss_list = []\n",
    "style_loss_list = []\n",
    "mrf_loss_list = []\n",
    "max_iter = 50\n",
    "show_iter = 50\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "pbar = tqdm(total=max_iter)\n",
    "while n_iter[0] <= max_iter:\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        opt_fms = vgg(opt_img, loss_layers)\n",
    "        \n",
    "        # Content & style loss\n",
    "        style_loss = 0\n",
    "        content_loss = 0\n",
    "        for a,A in enumerate(opt_fms[len(mrf_layers):]):\n",
    "            one_layer_loss = weights[a] * loss_fns[a](A, targets[a])\n",
    "            if a < len(style_layers):\n",
    "                style_loss += one_layer_loss\n",
    "            else:\n",
    "                content_loss += one_layer_loss\n",
    "\n",
    "        # MRF loss or energy function\n",
    "        mrf_loss = mrf_loss_fn(opt_fms[:len(mrf_layers)], style_patches_lists, weight_list,patch_size)\n",
    "                      \n",
    "        # Regularzier\n",
    "        regularizer = smoothnes_loss(opt_img)\n",
    "\n",
    "        # Total loss\n",
    "        # total_loss = alpha * content_loss + beta * style_loss + gamma * mrf_loss\n",
    "        total_loss = alpha * content_loss + beta * style_loss + gamma * mrf_loss + 0.001*regularizer\n",
    " \n",
    "        # log \n",
    "        content_loss_list.append(content_loss.item())\n",
    "        style_loss_list.append(style_loss.item())\n",
    "        loss_list.append(total_loss)\n",
    "\n",
    "        # Calculate backward\n",
    "        total_loss.backward()\n",
    "\n",
    "        #print loss\n",
    "        if (n_iter[0])%show_iter == 0:\n",
    "\n",
    "            tqdm.write('Iteration: {}'.format(naming_it[0]))\n",
    "            tqdm.write('Content loss : {}'.format(alpha*content_loss.item()))\n",
    "            tqdm.write('Style loss   : {}'.format(beta *style_loss.item()))\n",
    "            tqdm.write('MRF loss     : {}'.format(gamma*mrf_loss.item()))\n",
    "            tqdm.write('Regulari loss: {}'.format(0.001*regularizer.item()))\n",
    "            tqdm.write('Total loss   : {}'.format(total_loss.item()))\n",
    "            # pbar.write\n",
    "\n",
    "            # Save loss graph\n",
    "            plt.plot(loss_list, label='total loss')\n",
    "            plt.plot(content_loss_list, label='content loss')\n",
    "            plt.plot(style_loss_list, label='style loss')\n",
    "            plt.plot(mrf_loss_list, label='mrf loss')\n",
    "            plt.legend()\n",
    "            plt.savefig(output_path + 'loss_graph.jpg')\n",
    "            plt.close()\n",
    "            # Save optimized image\n",
    "            out_img = postp(opt_img.data[0].cpu().squeeze(), image_size, result_invert)\n",
    "            out_img.save(output_path + '{}.bmp'.format(naming_it[0]))\n",
    "\n",
    "        n_iter[0] += 1\n",
    "        naming_it[0] += 1\n",
    "        pbar.update(1)\n",
    "        return total_loss\n",
    "    optimizer.step(closure)\n",
    "pbar.close()\n",
    "# Save sum images\n",
    "save_images(content_img.data[0].cpu().squeeze(), style_img.data[0].cpu().squeeze(), opt_img.data[0].cpu().squeeze(), image_size, output_path, naming_it[0], content_invert, style_invert, result_invert)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Style transfer took {} seconds overall\".format(end-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
